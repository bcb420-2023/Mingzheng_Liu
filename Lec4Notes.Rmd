---
title: "BCB420_week4"
author: "Mingzheng liu"
date: "11/02/2022"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---
 BCB420 Lecture 4 Notes
---
# Overview

* Data Exploration: Data standards (MIAME & MINSEQE)
* Our dataset - A1 help
* Data Normalization: Why and what to do?
* Identifier Mapping: BiomaRt example (week5): Identifer mapping is important and the basis for all down stream analysis 

## Packages required
```{r}
if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")
if (!requireNamespace("GEOmetadb", quietly = TRUE)) BiocManager::install("GEOmetadb")
if (!requireNamespace("ggplot2", quietly = TRUE)) install.packages("ggplot2")
library(BiocManager)
library(GEOmetadb)
library(ggplot2)
library(knitr)
```


# Data Standards
Functional Genomics Data Society: MIAME & MINSEQE

### MIAME (Minimum Information About a Microarray Experiment)
* originally published in Nature genetics in 2001 
* represented the guiding principles of the minimal information needed for submitting a dataset
* The MIAME standard includes the following elements:

1. Raw data for each assay (e.g., CEL or FASTQ files)
2. Final processed (normalized) data for the set of assays in the study 
(e.g., the gene expression data count matrix used to draw the conclusions in the study)
3. Essential sample annotation (e.g., tissue, sex and age) and the experimental factors and their values (e.g., compound and dose in a dose response study)
4. Experimental design including sample data relationships (e.g., which raw data file relates to which sample, which assays are technical, which are biological replicates)
5. Sufficient annotation of the array or sequence features examines (e.g., gene identifiers, genomic coordinates)
6. Essential laboratory and data processing protocols (e.g., what normalization method has been used to obtain the final processed data)

### MINSEQE (Minimum Information about a high-throughput SEQuencing Experiment)
* reporting standard for nucleotide sequence experiments, such as RNA sequencing (RNA-seq) and DNA sequencing experiments

### Criticism of MIAME & MINSEQE
* different interpretations of the level of detail required to adequately report a microarray experiment
* debates as to whether there is a genuine benefit to making microarray data public

### Standards - Proteomics
* Proteomics Standards Initiative - PSI (Organization)
* standards and best practices for proteomics experiments.

# Data set example - GSE70072
Title of the paper - Apoptosis enhancing drugs overcome innate platinum resistance in CA125 negative tumor initiating populations of high grade serous ovarian cancer

* CA125
1. cell surface glycoprotein
2. highly expressed in high grade serous ovarian cancer and found in blood of effected patients.
3. a biomarker of the disease

## Data exploration: First things first get the GEO description of your dataset.
```{r}
gse <- getGEO("GSE70072",GSEMatrix=FALSE)
kable(data.frame(head(Meta(gse))), format = "html")
current_gpl <- names(GPLList(gse))[1]
current_gpl_info <- Meta(getGEO(current_gpl))
# information of the platform GPL11154
current_gpl_info$title
current_gpl_info$last_update_date
current_gpl_info$organism
```
## Get the expression Data 
```{r}
sfiles = getGEOSuppFiles('GSE70072')
fnames = rownames(sfiles)
# there is only one supplemental file
ca125_exp = read.delim(fnames[1],header=TRUE,check.names = FALSE)
```
Difference between:
```{r}
read.table(fnames[1],header=TRUE,check.names=FALSE,nrows = 1)[1,1:4]
read.table(fnames[1],header=TRUE,check.names=TRUE,nrows = 1)[1,1:4]
kable(ca125_exp[1:15,1:5], format = "html")
```
## Cleaning the data:
- How many unique genes do we have?
- Are there any non-genes in our dataset? If so what are they? 
- Can we exclude them?
```{r}
# How many genes do we have measurments for?
dim(ca125_exp)
# Define the groups
colnames(ca125_exp)
#get the 2 and third token from the column names
samples <- data.frame(lapply(colnames(ca125_exp)[3:22], FUN=function(x){unlist(strsplit(x,
                        split = "\\."))[c(2,3)]}))
colnames(samples) <- colnames(ca125_exp)[3:22]
rownames(samples) <- c("patients","cell_type")
samples <- data.frame(t(samples))
```
Are any of genes duplicated? and Why?
```{r}
# Get the summarized counts for each gene
summarized_gene_counts <- sort(table(ca125_exp$gname),decreasing = TRUE)
# What does table functions do? kable(table(ca125_exp$gname)[1:3], format="html")
kable(table(ca125_exp$gname)[1:3], format="html")
# Only output those that are greater than 1
kable(summarized_gene_counts[which(summarized_gene_counts>1)[1:10]],format="html")
```
* Y_RNA - small non-coding RNAs 
* SNOR - small nucleolar RNA
* U - small nuclear RNA
Not filter above if we base our analysis on ensembl gene ids then they are unique elements and we don't have to worry about them.

### But we do need to filter out genes that have low counts!
* According to the edgeR protocol - Filter weakly expressed and noninformative (e.g., non-aligned) features.
* In edgeR, it is recommended to remove features without at least 1 read per million in n of the samples, where n is the size of the smallest group of replicates.
* For the example dataset - there are 10 samples of each group so n=10
```{r}
if (!requireNamespace("edgeR", quietly = TRUE)) BiocManager::install("edgeR")
library("edgeR")

#translate out counts into counts per million using #the edgeR package function cpm
cpms = cpm(ca125_exp[,3:22])
rownames(cpms) <- ca125_exp[,1]

# get rid of low counts
keep = rowSums(cpms >1) >=10
ca125_exp_filtered = ca125_exp[keep,]
dim(ca125_exp_filtered)
# Check Does that solve some of duplicate issues?
summarized_gene_counts_filtered <- sort(table(ca125_exp_filtered$gname), decreasing = TRUE)
kable(summarized_gene_counts_filtered[which(summarized_gene_counts_filtered>1)[1:10]],format="html")
```

# Data Normalization 
* Adjust the raw data to account for variations that arise because of the experiment and prevent direct comparison of the multiple samples.
* Normalization by library size_ total count normalizations & RPKM (read per kilobase per million mapped reads), FPKM (fragments per kilobase per million mapped reads)
* Data distributions - normalizing by distribution
e.g. Normal distribution
```{r}
# Generate a set of 1000 randomly selected numbers from the normal distribution.
r <- rnorm(1000, mean=0, sd=1)
# If we graph this random distribution it will look like:
hist(r,freq = FALSE,breaks = 30,
     xlim = c(-4, 4),ylim = c(0, 1),
     main = "Normal Distribution",
     xlab = "x",ylab = "f(x)", col = "yellow")
# If we then grab 100 values equally spaced between -4 and 4
hist(r,freq = FALSE,breaks = 30,
     xlim = c(-4, 4),ylim = c(0, 1),
     main = "Normal Distribution",
     xlab = "x",ylab = "f(x)", col = "yellow")
x <- seq(-4, 4, length.out = 100)
#add the density distribution
points(x, dnorm(x), type = "l", lwd = 2, col="firebrick")

### Distribution of our data - Boxplot
data2plot <- log2(cpm(ca125_exp_filtered[,3:22]))
boxplot(data2plot, xlab = "Samples", ylab = "log2 CPM",
        las = 2, cex = 0.5, cex.lab = 0.5,
        cex.axis = 0.5, main = "CA125 RNASeq Samples")
#draw the median on each box plot
abline(h = median(apply(data2plot, 2, median)),
       col = "green", lwd = 0.6, lty = "dashed")

### Distribution of our data - Density plot
counts_density <- apply(log2(cpm(ca125_exp_filtered[,3:22])),
                        2, density)
  #calculate the limits across all the samples
xlim <- 0; ylim <- 0
for (i in 1:length(counts_density)) {
      xlim <- range(c(xlim, counts_density[[i]]$x));
      ylim <- range(c(ylim, counts_density[[i]]$y))
    }
    cols <- rainbow(length(counts_density))
    ltys <- rep(1, length(counts_density))
    #plot the first density plot to initialize the plot
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n",
         ylab="Smoothing density of log2-CPM",
         main="", cex.lab = 0.85)
    #plot each line
for (i in 1:length(counts_density)) lines(counts_density[[i]], col=cols[i], lty=ltys[i])
    #create legend
    legend("topright", colnames(data2plot),
           col=cols, lty=ltys, cex=0.75,
           border ="blue",  text.col = "green4",
           merge = TRUE, bg = "gray90")
```

## Normalizing by Distribution- Assumptions
* Differentially expressed and non-differentially expressed genes behave the same way. Technical variations in the data will effect both.
* The data is roughly balanced - a gene that is up regulated is one sample is correspondingly down-regulated in the other sample. There are similiar number of up and down regulated genes.
